{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-automated-image-classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOECf1poX8EixxhrEq/qgNi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/automl-experiments/blob/main/automl-in-action/04-end-to-end-ml-solutions/01_automated_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Addressing tasks with multiple inputs or outputs"
      ],
      "metadata": {
        "id": "VBSFJvOUdsL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An ML task could involve multiple inputs collected from different resources, which we\n",
        "call different data modalities.\n",
        "\n",
        "For example, images could be associated with tags and\n",
        "other text descriptions, and videos could contain both visual and acoustic information\n",
        "(as well as metadata) that is useful for classification.\n",
        "\n",
        "Multiple inputs augment information\n",
        "resources. They could benefit and compensate with each other to help train a\n",
        "better ML model. This approach is called multi-input learning or multimodal learning.\n",
        "\n",
        "Similarly, we might want to have multiple outputs corresponding to different tasks\n",
        "(regression or classification) that we address simultaneously. This is called multi-output\n",
        "learning or multitask learning.\n"
      ],
      "metadata": {
        "id": "1_cNTUjQdzaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "CQG0hihvdzxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras==1.0.18\n",
        "!pip install keras-tuner==1.1.0"
      ],
      "metadata": {
        "id": "s_JdLhOuePhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import autokeras as ak"
      ],
      "metadata": {
        "id": "9O7SzjGGeZ4y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Automated image classification"
      ],
      "metadata": {
        "id": "-rmcdXcud0AZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The IO API can generalize to all types of data and tasks, so\n",
        "we need to provide information about the data types and task types during initialization,\n",
        "so it can select the appropriate loss function, metrics, search space, and\n",
        "search objective."
      ],
      "metadata": {
        "id": "QmU0vSsrfYoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"Training image shape:\", x_train.shape)  # (60000, 28, 28)\n",
        "print(\"Training label shape:\", y_train.shape)  # (60000,)\n",
        "print(\"First five training labels:\", y_train[:5])  # array([5 0 4 1 9], dtype=uint8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHI1eDr7fETw",
        "outputId": "5d3c9d44-5247-413d-a2b0-16625d631aff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training image shape: (60000, 28, 28)\n",
            "Training label shape: (60000,)\n",
            "First five training labels: [5 0 4 1 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the IO API\n",
        "io_model = ak.AutoModel(\n",
        "    inputs=ak.ImageInput(),\n",
        "    outputs=ak.ClassificationHead(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]),\n",
        "    objective=\"val_loss\",\n",
        "    tuner=\"random\",\n",
        "    max_trials=3,\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "# Fit the model with prepared data\n",
        "io_model.fit(x_train[:100], y_train[:100], epochs=1)\n",
        "# Use the first 100 training samples for 1 epoch as a quick demo.\n",
        "# You may run with the full dataset with 10 epochs, but expect a longer training time."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBhR9dNbfmC2",
        "outputId": "3cc66326-d9ce-446f-9cad-dfb545bbff2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 48s]\n",
            "val_loss: 2.30248761177063\n",
            "\n",
            "Best val_loss So Far: 2.30248761177063\n",
            "Total elapsed time: 00h 01m 19s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "4/4 [==============================] - 27s 5s/step - loss: 2.3511 - accuracy: 0.1200\n",
            "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f30f9399310>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the summarized results during the tuning process\n",
        "io_model.tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7AXKZn6gmdw",
        "outputId": "caf0eaed-352e-4690-d0b8-06d8b14dc5ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./auto_model\n",
            "Showing 10 best trials\n",
            "Objective(name='val_loss', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "image_block_1/normalize: True\n",
            "image_block_1/augment: False\n",
            "image_block_1/block_type: xception\n",
            "classification_head_1/spatial_reduction_1/reduction_type: global_avg\n",
            "classification_head_1/dropout: 0.5\n",
            "optimizer: adam\n",
            "learning_rate: 1e-05\n",
            "image_block_1/xception_block_1/pretrained: False\n",
            "image_block_1/xception_block_1/imagenet_size: False\n",
            "Score: 2.30248761177063\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "image_block_1/normalize: True\n",
            "image_block_1/augment: True\n",
            "image_block_1/block_type: vanilla\n",
            "classification_head_1/spatial_reduction_1/reduction_type: global_avg\n",
            "classification_head_1/dropout: 0.5\n",
            "optimizer: adam\n",
            "learning_rate: 2e-05\n",
            "image_block_1/image_augmentation_1/translation_factor: 0.0\n",
            "image_block_1/image_augmentation_1/horizontal_flip: True\n",
            "image_block_1/image_augmentation_1/vertical_flip: True\n",
            "image_block_1/image_augmentation_1/rotation_factor: 0.0\n",
            "image_block_1/image_augmentation_1/zoom_factor: 0.0\n",
            "image_block_1/image_augmentation_1/contrast_factor: 0.0\n",
            "image_block_1/conv_block_1/kernel_size: 3\n",
            "image_block_1/conv_block_1/separable: False\n",
            "image_block_1/conv_block_1/max_pooling: True\n",
            "image_block_1/conv_block_1/dropout: 0\n",
            "image_block_1/conv_block_1/num_blocks: 2\n",
            "image_block_1/conv_block_1/num_layers: 2\n",
            "image_block_1/conv_block_1/filters_0_0: 32\n",
            "image_block_1/conv_block_1/filters_0_1: 32\n",
            "image_block_1/conv_block_1/filters_1_0: 32\n",
            "image_block_1/conv_block_1/filters_1_1: 32\n",
            "Score: 2.334766387939453\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "image_block_1/normalize: False\n",
            "image_block_1/augment: False\n",
            "image_block_1/block_type: resnet\n",
            "image_block_1/res_net_block_1/pretrained: True\n",
            "image_block_1/res_net_block_1/version: resnet101_v2\n",
            "image_block_1/res_net_block_1/imagenet_size: False\n",
            "classification_head_1/spatial_reduction_1/reduction_type: flatten\n",
            "classification_head_1/dropout: 0.25\n",
            "optimizer: adam\n",
            "learning_rate: 0.1\n",
            "image_block_1/res_net_block_1/trainable: False\n",
            "Score: 9286.0849609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve best model\n",
        "best_model = io_model.export_model()\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgIxu-rAgrWQ",
        "outputId": "bbc52956-3fb1-4ac9-eaf5-0f1ad7e01cc5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 28, 28)]     0           []                               \n",
            "                                                                                                  \n",
            " cast_to_float32 (CastToFloat32  (None, 28, 28)      0           ['input_1[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " expand_last_dim (ExpandLastDim  (None, 28, 28, 1)   0           ['cast_to_float32[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, 28, 28, 1)    3           ['expand_last_dim[0][0]']        \n",
            "                                                                                                  \n",
            " resizing (Resizing)            (None, 71, 71, 1)    0           ['normalization[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 71, 71, 3)    0           ['resizing[0][0]',               \n",
            "                                                                  'resizing[0][0]',               \n",
            "                                                                  'resizing[0][0]']               \n",
            "                                                                                                  \n",
            " xception (Functional)          (None, 3, 3, 2048)   20861480    ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['xception[0][0]']               \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           20490       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " classification_head_1 (Softmax  (None, 10)          0           ['dense[0][0]']                  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,881,973\n",
            "Trainable params: 20,827,442\n",
            "Non-trainable params: 54,531\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict with the best model\n",
        "predicted_y = io_model.predict(x_test[:100])\n",
        "print(predicted_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNXXNGdgg0ZN",
        "outputId": "2838e63e-f5df-401f-d3bc-d71a2f3e8748"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 521ms/step\n",
            "[['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['1']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']\n",
            " ['1']\n",
            " ['9']\n",
            " ['9']\n",
            " ['9']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model on the test data\n",
        "test_loss, test_acc = io_model.evaluate(x_test[:100], y_test[:100])\n",
        "print(\"Test accuracy: \", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6hjXCs4hCwF",
        "outputId": "6daa02b2-9718-4efb-c1e4-220de60d7467"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 3s 514ms/step - loss: 2.3025 - accuracy: 0.1200\n",
            "Test accuracy:  0.11999999731779099\n"
          ]
        }
      ]
    }
  ]
}