{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-fine-tuning-powerful-image-classifier.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM6wjI1qvVCbWRcpWBynLRC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/automl-experiments/blob/main/automated-machine-learning-with-autokeras/04-image-classification-and-regression/1_fine_tuning_powerful_image_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JJoEm7vDgta"
      },
      "source": [
        "##Fine-tuning a powerful image classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JWCBXCEDpou"
      },
      "source": [
        "The model we are going to create will classify images from a dataset called Canadian\n",
        "Institute for Advanced Research, 10 classes (CIFAR-10). It contains 60,000 32x32 red,\n",
        "green, blue (RGB) colored images, classified into 10 different classes. It is a collection of\n",
        "images that is commonly used to train ML and computer vision algorithms.\n",
        "\n",
        "<img src='images/1.png?raw=1' width='800'/>\n",
        "\n",
        "This a problem considered already solved. It is relatively easy to achieve a classification\n",
        "accuracy close to 80%. For better performance, we must use deep learning CNNs with\n",
        "which a classification precision greater than 90% can be achieved in the test dataset. Let's\n",
        "see how to implement it with AutoKeras.\n",
        "\n",
        "This is a classification task, so we can use the ImageClassifier class. This class\n",
        "generates and tests different models and hyperparameters, returning an optimal classifier\n",
        "to categorize each image with its corresponding class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tAZJ3aiEYDN"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLDcLjeiEZBn"
      },
      "source": [
        "!pip3 -q install autokeras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOTtbJ9yEhlt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import autokeras as ak\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import callbacks as tf_callbacks\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkNQIFl_IoXK"
      },
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSwP2YIHE2Eh"
      },
      "source": [
        "##Getting the CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHCi1M4QE2zc"
      },
      "source": [
        "We have to first load the CIFAR-10 dataset in\n",
        "memory and have a quick look at the dataset shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXbuIx9lE5V_",
        "outputId": "c4de1240-1860-4110-bf6b-2d18101d2e5e"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape) \n",
        "print(x_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78J_e-ncFSff"
      },
      "source": [
        "Although it is a well-known machine learning dataset, it is always important to ensure\n",
        "that the data is distributed evenly, to avoid surprises."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "qhon3K3TFTCq",
        "outputId": "f1d7b91f-a6a3-4abf-e9aa-0bdc03958313"
      },
      "source": [
        "train_histogram = np.histogram(y_train)\n",
        "test_histogram = np.histogram(y_test)\n",
        "\n",
        "_, axs = plt.subplots(1, 2)\n",
        "axs[0].set_xticks(range(10))\n",
        "axs[0].bar(range(10), train_histogram[0])\n",
        "axs[0].set_title('Train dataset histogram')\n",
        "\n",
        "axs[1].set_xticks(range(10))\n",
        "axs[1].bar(range(10), test_histogram[0])\n",
        "axs[1].set_title('Test dataset histogram')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BumEpo2FmPs"
      },
      "source": [
        "##Creating and training the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsJl6NN4Fup-"
      },
      "source": [
        "We will now use the AutoKeras ImageClassifier class to find the best classification\n",
        "model. Just for this little example, we set max_trials (the maximum number of\n",
        "different Keras models to try) to 2, and we do not set the epochs parameter so that it will\n",
        "use an adaptive number of epochs automatically. For real use, it is recommended to set\n",
        "a large number of trials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "M_zRdt9HFxT-",
        "outputId": "b77b5d4c-2201-468a-8d5b-2291f2a9e526"
      },
      "source": [
        "#Initialize the ImageClassifier\n",
        "clf = ak.ImageClassifier(max_trials=1)\n",
        "# Search for the best model\n",
        "clf.fit(x_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./image_classifier/oracle.json\n",
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "image_block_1/b...|vanilla           |?                 \n",
            "image_block_1/n...|True              |?                 \n",
            "image_block_1/a...|False             |?                 \n",
            "image_block_1/c...|3                 |?                 \n",
            "image_block_1/c...|1                 |?                 \n",
            "image_block_1/c...|2                 |?                 \n",
            "image_block_1/c...|True              |?                 \n",
            "image_block_1/c...|False             |?                 \n",
            "image_block_1/c...|0.25              |?                 \n",
            "image_block_1/c...|32                |?                 \n",
            "image_block_1/c...|64                |?                 \n",
            "classification_...|flatten           |?                 \n",
            "classification_...|0.5               |?                 \n",
            "optimizer         |adam              |?                 \n",
            "learning_rate     |0.001             |?                 \n",
            "\n",
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b3ac0291c400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Search for the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/tasks/image.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         )\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/auto_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         )\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         super().search(\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         )\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         _, history = utils.fit_with_adaptive_batch_size(\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/utils/utils.py\u001b[0m in \u001b[0;36mfit_with_adaptive_batch_size\u001b[0;34m(model, batch_size, **fit_kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_with_adaptive_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     history = run_with_adaptive_batch_size(\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/utils/utils.py\u001b[0m in \u001b[0;36mrun_with_adaptive_batch_size\u001b[0;34m(batch_size, func, **fit_kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceExhaustedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/utils/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_with_adaptive_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     history = run_with_adaptive_batch_size(\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv2d/Relu (defined at /usr/local/lib/python3.7/dist-packages/autokeras/utils/utils.py:88) ]] [Op:__inference_train_function_18203]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVepJSdQGkrO"
      },
      "source": [
        "As it has to process thousands of color images, the models that AutoKeras will generate\n",
        "will be more expensive to train, so this process will take hours, even using graphics\n",
        "processing units (GPUs). We have limited the search to five architectures (max_trials\n",
        "= 5). Increasing this number would give us a more accurate model, although it would\n",
        "also take longer to finish."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIJ4zP1IGmto"
      },
      "source": [
        "##Improving the model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QNorO2kGniB"
      },
      "source": [
        ""
      ]
    }
  ]
}