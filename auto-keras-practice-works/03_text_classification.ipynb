{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-text-classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMpin02DW4+ns3uJyGvpamY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/automl-experiments/blob/main/auto-keras-practice-works/03_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Classification"
      ],
      "metadata": {
        "id": "9P38aUZKccB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "https://autokeras.com/tutorial/text_classification/"
      ],
      "metadata": {
        "id": "5aW4aaOpcdPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install autokeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex89EZgGcj_4",
        "outputId": "4d5397d8-967a-4145-cbd4-88f5fcf7c79c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 30 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 40 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 51 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 71 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 92 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 166 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 454.4 MB 22 kB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 35.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 36.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 59.7 MB/s \n",
            "\u001b[?25h  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "import autokeras as ak"
      ],
      "metadata": {
        "id": "ctlp6HJmcnfe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A Simple Example"
      ],
      "metadata": {
        "id": "6mKrm7wYcqfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step is to prepare your data. Here we use the IMDB dataset as an example."
      ],
      "metadata": {
        "id": "RTgU8K-LcrH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.utils.get_file(fname=\"aclImdb.tar.gz\",\n",
        "                                  origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "                                  extract=True)\n",
        "\n",
        "# set path to dataset\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
        "\n",
        "classes = [\"neg\", \"pos\"]\n",
        "train_data = load_files(os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes)\n",
        "test_data = load_files(os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes)\n",
        "\n",
        "x_train = np.array(train_data.data)\n",
        "y_train = np.array(train_data.target)\n",
        "x_test = np.array(test_data.data)\n",
        "y_test = np.array(test_data.target)\n",
        "\n",
        "print(x_train.shape)  # (25000,)\n",
        "print(y_train.shape)  # (25000, 1)\n",
        "print(x_train[0][:50])  # this film was just brilliant casting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQpgFjH8ctfW",
        "outputId": "88d80107-9949-450b-db6b-06aa20d35b6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,)\n",
            "(25000,)\n",
            "b'Zero Day leads you to think, even re-think why two'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second step is to run the TextClassifier. As a quick demo, we set epochs to 2.\n",
        "\n",
        "You can also leave the epochs unspecified for an adaptive number of epochs."
      ],
      "metadata": {
        "id": "uZ2-UnzyeQ3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the text classifier\n",
        "clf = ak.TextClassifier(overwrite=True, max_trials=1)\n",
        "# Feed the text classifier with training data\n",
        "clf.fit(x_train, y_train, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkxJ5quReRVN",
        "outputId": "ad173a8b-060d-4ca9-8c33-f42e19b24cf4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 04m 46s]\n",
            "val_loss: 0.27647531032562256\n",
            "\n",
            "Best val_loss So Far: 0.27647531032562256\n",
            "Total elapsed time: 00h 04m 46s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 168s 213ms/step - loss: 0.4293 - accuracy: 0.7826\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 167s 213ms/step - loss: 0.2376 - accuracy: 0.9039\n",
            "INFO:tensorflow:Assets written to: ./text_classifier/best_model/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac8ae793d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict with the best model\n",
        "predicted_y = clf.predict(x_test)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWj3-mToex51",
        "outputId": "3d8ca0a0-50ea-4495-b66a-17582264f7a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 45s 57ms/step\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 0.2690 - accuracy: 0.8910\n",
            "[0.2690293490886688, 0.891040027141571]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Validation Data"
      ],
      "metadata": {
        "id": "IgzWQQjsfNdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, AutoKeras use the last 20% of training data as validation data. \n",
        "\n",
        "As shown in the example below, you can use `validation_split` to specify the percentage."
      ],
      "metadata": {
        "id": "IMB86htvfPWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Split the training data and use the last 15% as validation data.\n",
        "    validation_split=0.15,\n",
        ")"
      ],
      "metadata": {
        "id": "-unf4YnPfTd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use your own validation set instead of splitting it from the training data with `validation_data`."
      ],
      "metadata": {
        "id": "n56xfKFBfZxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split = 5000\n",
        "x_val = x_train[split:]\n",
        "y_val = y_train[split:]\n",
        "x_train = x_train[:split]\n",
        "y_train = y_train[:split]\n",
        "\n",
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=2,\n",
        "    # Use your own validation set.\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "metadata": {
        "id": "3UfgLuazfc5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Customized Search Space"
      ],
      "metadata": {
        "id": "swA_qfT1fhbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For advanced users, you may customize your search space by using AutoModel instead of TextClassifier. You can configure the TextBlock for some high-level configurations, e.g., vectorizer for the type of text vectorization method to use. \n",
        "\n",
        "You can use 'sequence', which uses TextToInteSequence to convert the words to integers and use Embedding for embedding the integer sequences, or you can use 'ngram', which uses TextToNgramVector to vectorize the sentences. You can also do not specify these arguments, which would leave the different choices to be tuned automatically. "
      ],
      "metadata": {
        "id": "hniBJ74mfiR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextBlock(block_type=\"ngram\")(input_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "\n",
        "clf = ak.AutoModel(inputs=input_node, outputs=output_node, overwrite=True, max_trials=1)\n",
        "clf.fit(x_train, y_train, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Y6yukgf5Nd",
        "outputId": "9f18a726-0c60-4626-f69a-a6cfb26ff514"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 01m 02s]\n",
            "val_loss: 0.32131633162498474\n",
            "\n",
            "Best val_loss So Far: 0.32131633162498474\n",
            "Total elapsed time: 00h 01m 02s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.3670 - accuracy: 0.8457\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.2554 - accuracy: 0.8957\n",
            "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac8ac39f10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The usage of AutoModel is similar to the functional API of Keras. Basically, you are building a graph, whose edges are blocks and the nodes are intermediate outputs of blocks. To add an edge from `input_node` to `output_node` with `output_node = ak.[some_block]([block_args])(input_node)`.\n",
        "\n",
        "You can even also use more fine grained blocks to customize the search space even further."
      ],
      "metadata": {
        "id": "1-9un-32iuuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextToIntSequence()(input_node)\n",
        "output_node = ak.Embedding()(output_node)\n",
        "# Use separable Conv layers in Keras.\n",
        "output_node = ak.ConvBlock(separable=True)(output_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "\n",
        "clf = ak.AutoModel(inputs=input_node, outputs=output_node, overwrite=True, max_trials=1)\n",
        "clf.fit(x_train, y_train, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nYfWbfZi1xJ",
        "outputId": "733ad4bd-1d6b-4ee6-fe64-db535e136a7c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 02m 49s]\n",
            "val_loss: 0.6931466460227966\n",
            "\n",
            "Best val_loss So Far: 0.6931466460227966\n",
            "Total elapsed time: 00h 02m 49s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 50s 62ms/step - loss: 0.6932 - accuracy: 0.4952\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 50s 63ms/step - loss: 0.6932 - accuracy: 0.4958\n",
            "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac8b8d9a10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Format"
      ],
      "metadata": {
        "id": "0TJ36h8Ljc23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AutoKeras TextClassifier is quite flexible for the data format.\n",
        "\n",
        "For the text, the input data should be one-dimensional For the classification labels, AutoKeras accepts both plain labels, i.e. strings or integers, and one-hot encoded encoded labels, i.e. vectors of 0s and 1s.\n",
        "\n",
        "We also support using tf.data.Dataset format for the training data."
      ],
      "metadata": {
        "id": "rBd_8ryojdbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (y_train,))).batch(32)\n",
        "test_set = tf.data.Dataset.from_tensor_slices(((x_test,), (y_test,))).batch(32)\n",
        "\n",
        "clf = ak.TextClassifier(overwrite=True, max_trials=2)\n",
        "# Feed the tensorflow Dataset to the classifier.\n",
        "clf.fit(train_set, epochs=2)\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(test_set)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4W2zZ1hjyw9",
        "outputId": "fdcf8a52-db1d-45ec-a506-d57339ee2fd8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 04m 50s]\n",
            "val_loss: 0.3088071644306183\n",
            "\n",
            "Best val_loss So Far: 0.2812400162220001\n",
            "Total elapsed time: 00h 10m 45s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 172s 219ms/step - loss: 0.4378 - accuracy: 0.7770\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 171s 219ms/step - loss: 0.2455 - accuracy: 0.9023\n",
            "INFO:tensorflow:Assets written to: ./text_classifier/best_model/assets\n",
            "782/782 [==============================] - 48s 62ms/step\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 0.2734 - accuracy: 0.8900\n",
            "[0.2734043300151825, 0.889959990978241]\n"
          ]
        }
      ]
    }
  ]
}