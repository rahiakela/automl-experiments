{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-text-regression.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMyoeNEZPStHFNaE/rIBiHo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/automl-experiments/blob/main/auto-keras-practice-works/04_text_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Regression"
      ],
      "metadata": {
        "id": "nWbft-lBdQQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "https://autokeras.com/tutorial/text_regression/"
      ],
      "metadata": {
        "id": "1cW9325KdQ2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install autokeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4o0WBHXdUC7",
        "outputId": "96e4d41d-0917-4774-c3af-5b551b0057ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 166 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 454.4 MB 19 kB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 39.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 36.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 22.2 MB/s \n",
            "\u001b[?25h  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "import autokeras as ak"
      ],
      "metadata": {
        "id": "zhbC6yygdabd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make this tutorial easy to follow, we just treat IMDB dataset as a regression dataset. It means we will treat prediction targets of IMDB dataset, which are 0s and 1s as numerical values, so that they can be directly used as the regression targets."
      ],
      "metadata": {
        "id": "j_H8Gh3aerzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A Simple Example"
      ],
      "metadata": {
        "id": "BM92wnd8esW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step is to prepare your data. Here we use the IMDB dataset as an example."
      ],
      "metadata": {
        "id": "bd8VKT3JeuRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\",\n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    extract=True,\n",
        ")\n",
        "\n",
        "# set path to dataset\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
        "\n",
        "classes = [\"pos\", \"neg\"]\n",
        "train_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes\n",
        ")\n",
        "test_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes\n",
        ")\n",
        "\n",
        "x_train = np.array(train_data.data)\n",
        "y_train = np.array(train_data.target)\n",
        "x_test = np.array(test_data.data)\n",
        "y_test = np.array(test_data.target)\n",
        "\n",
        "print(x_train.shape)  # (25000,)\n",
        "print(y_train.shape)  # (25000, 1)\n",
        "print(x_train[0][:50])  # <START> this film was just brilliant casting <UNK>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xiyg2-11exWL",
        "outputId": "238f388b-ced7-463b-eb55-ff5219c658d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 7s 0us/step\n",
            "(25000,)\n",
            "(25000,)\n",
            "b'Zero Day leads you to think, even re-think why two'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second step is to run the TextRegressor. As a quick demo, we set epochs to 2. You can also leave the epochs unspecified for an adaptive number of epochs."
      ],
      "metadata": {
        "id": "B6U7AGvWe3FM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the text regressor.\n",
        "reg = ak.TextRegressor(overwrite=True, max_trials=1)\n",
        "\n",
        "# Feed the text regressor with training data.\n",
        "reg.fit(x_train, y_train, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAd7hvwoezl6",
        "outputId": "505eeecd-6f36-4c18-c535-4a7216556172"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 01m 29s]\n",
            "val_loss: 0.15182562172412872\n",
            "\n",
            "Best val_loss So Far: 0.15182562172412872\n",
            "Total elapsed time: 00h 01m 29s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 30s 37ms/step - loss: 0.1847 - mean_squared_error: 0.1847\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 0.1235 - mean_squared_error: 0.1235\n",
            "INFO:tensorflow:Assets written to: ./text_regressor/best_model/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29ee3b8150>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict with the best model\n",
        "predicted_y = reg.predict(x_test)\n",
        "# Evaluate the best model with testing data\n",
        "print(reg.evaluate(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V5iAIdJfP-c",
        "outputId": "c02ec20a-59e4-4272-e9e6-9e61a09bc79c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 9ms/step\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.1533 - mean_squared_error: 0.1533\n",
            "[0.15334804356098175, 0.15334804356098175]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Validation Data"
      ],
      "metadata": {
        "id": "hq4Ryk9Yfb1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, AutoKeras use the last 20% of training data as validation data. As shown in the example below, you can use `validation_split` to specify the percentage."
      ],
      "metadata": {
        "id": "nQ3feRYhfd28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Split the training data and use the last 15% as validation data.\n",
        "    validation_split=0.15,\n",
        ")"
      ],
      "metadata": {
        "id": "-MXnuA5KfgIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use your own validation set instead of splitting it from the training data with `validation_data`."
      ],
      "metadata": {
        "id": "VZSRaggjfjUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split = 5000\n",
        "x_val = x_train[split:]\n",
        "y_val = y_train[split:]\n",
        "x_train = x_train[:split]\n",
        "y_train = y_train[:split]\n",
        "\n",
        "reg.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=2,\n",
        "    # Use your own validation set.\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "metadata": {
        "id": "XeDAzOK6fmII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Customized Search Space"
      ],
      "metadata": {
        "id": "mYBIy9MFfrT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For advanced users, you may customize your search space by using AutoModel instead of TextRegressor. You can configure the TextBlock for some high-level configurations, e.g., vectorizer for the type of text vectorization method to use. You can use 'sequence', which uses TextToInteSequence to convert the words to integers and use Embedding for embedding the integer sequences, or you can use 'ngram', which uses TextToNgramVector to vectorize the sentences. You can also do not specify these arguments, which would leave the different choices to be tuned automatically."
      ],
      "metadata": {
        "id": "MxOE83HOfr7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextBlock(block_type=\"ngram\")(input_node)\n",
        "output_node = ak.RegressionHead()(output_node)\n",
        "\n",
        "reg = ak.AutoModel(inputs=input_node, outputs=output_node, overwrite=True, max_trials=1)\n",
        "reg.fit(x_train, y_train, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fup9UCcHf1na",
        "outputId": "52eb3a92-ba4a-4069-f10f-a4d133ba212d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 00m 51s]\n",
            "val_loss: 0.4516303837299347\n",
            "\n",
            "Best val_loss So Far: 0.4516303837299347\n",
            "Total elapsed time: 00h 00m 51s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 10s 11ms/step - loss: 0.6867 - mean_squared_error: 0.6867\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.1292 - mean_squared_error: 0.1292\n",
            "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29eed33550>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The usage of AutoModel is similar to the functional API of Keras. Basically, you are building a graph, whose edges are blocks and the nodes are intermediate outputs of blocks. To add an edge from input_node to `output_node` with `output_node = ak.[some_block]([block_args])(input_node)`.\n",
        "\n",
        "You can even also use more fine grained blocks to customize the search space even further."
      ],
      "metadata": {
        "id": "Yy1o4jzsf80F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextToIntSequence()(input_node)\n",
        "output_node = ak.Embedding()(output_node)\n",
        "# Use separable Conv layers in Keras.\n",
        "output_node = ak.ConvBlock(separable=True)(output_node)\n",
        "output_node = ak.RegressionHead()(output_node)\n",
        "\n",
        "reg = ak.AutoModel(inputs=input_node, outputs=output_node, overwrite=True, max_trials=1)\n",
        "reg.fit(x_train, y_train, epochs=2)"
      ],
      "metadata": {
        "id": "StBV9Zn0gAEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Format"
      ],
      "metadata": {
        "id": "JU7BUT8xgLkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AutoKeras TextRegressor is quite flexible for the data format.\n",
        "\n",
        "For the text, the input data should be one-dimensional For the regression targets, it should be a vector of numerical values. AutoKeras accepts numpy.ndarray.\n",
        "\n",
        "We also support using tf.data.Dataset format for the training data."
      ],
      "metadata": {
        "id": "mzyy7hp_gMIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (y_train,))).batch(32)\n",
        "test_set = tf.data.Dataset.from_tensor_slices(((x_test,), (y_test,))).batch(32)\n",
        "\n",
        "reg = ak.TextRegressor(overwrite=True, max_trials=2)\n",
        "# Feed the tensorflow Dataset to the regressor.\n",
        "reg.fit(train_set, epochs=2)\n",
        "# Predict with the best model.\n",
        "predicted_y = reg.predict(test_set)\n",
        "# Evaluate the best model with testing data.\n",
        "print(reg.evaluate(test_set))"
      ],
      "metadata": {
        "id": "uDe174p8gOqF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}